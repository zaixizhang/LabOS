"""
LabOS Database Tools -- biomedical database query functions.

Adapted from the STELLA database_tools module.  Every ``@tool``-decorated
function is a self-contained query helper for a public biomedical REST /
GraphQL API (UniProt, KEGG, HPO, BLAST, Entrez, NCBI, etc.).

LLM calls go through ``labos.tools.llm`` so the caller only needs an
OPENROUTER_API_KEY in the environment.
"""

import json
import os
import pickle
import time
import traceback
from typing import Any, Dict, List, Optional, Set, Union

import requests
from smolagents import tool

from labos.tools.llm import json_llm_call, simple_llm_call

# ---------------------------------------------------------------------------
# Resource / schema paths
# ---------------------------------------------------------------------------

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
_LABOS_ROOT = os.path.dirname(SCRIPT_DIR)  # labos package root

# Schema database shipped with the STELLA resource bundle.
# Fall back to a sibling ``resource/schema_db`` directory relative to the
# agents/STELLA installation when the LabOS tree does not carry its own copy.
_CANDIDATE_SCHEMA_PATHS = [
    os.path.join(_LABOS_ROOT, "resource", "schema_db"),
    os.path.join(os.path.expanduser("~"), "agents", "STELLA", "resource", "schema_db"),
]
SCHEMA_DB_PATH: str = ""
for _p in _CANDIDATE_SCHEMA_PATHS:
    if os.path.isdir(_p):
        SCHEMA_DB_PATH = _p
        break

_CANDIDATE_RESOURCE_PATHS = [
    os.path.join(_LABOS_ROOT, "resource"),
    os.path.join(os.path.expanduser("~"), "agents", "STELLA", "resource"),
]
RESOURCE_DIR: str = ""
for _p in _CANDIDATE_RESOURCE_PATHS:
    if os.path.isdir(_p):
        RESOURCE_DIR = _p
        break


# ---------------------------------------------------------------------------
# HPO OBO parser (utility, not a tool)
# ---------------------------------------------------------------------------

def parse_hpo_obo(obo_file_path: str) -> Dict[str, str]:
    """
    Simple HPO OBO file parser to extract term IDs and names.

    Args:
        obo_file_path: Path to the HPO OBO file.

    Returns:
        Dictionary mapping HPO IDs to names.
    """
    hpo_dict: Dict[str, str] = {}
    if not os.path.isabs(obo_file_path):
        obo_file_path = os.path.join(SCRIPT_DIR, obo_file_path)
    try:
        if not os.path.exists(obo_file_path):
            print(f"Warning: HPO OBO file not found at {obo_file_path}")
            return hpo_dict
        with open(obo_file_path, "r", encoding="utf-8") as f:
            current_term: Dict[str, str] = {}
            in_term_block = False
            for line in f:
                line = line.strip()
                if line == "[Term]":
                    in_term_block = True
                    current_term = {}
                elif line == "" and in_term_block:
                    if "id" in current_term and "name" in current_term:
                        hpo_dict[current_term["id"]] = current_term["name"]
                    in_term_block = False
                elif in_term_block and ":" in line:
                    key, value = line.split(":", 1)
                    key = key.strip()
                    value = value.strip()
                    if key == "id":
                        current_term["id"] = value
                    elif key == "name":
                        current_term["name"] = value
            if in_term_block and "id" in current_term and "name" in current_term:
                hpo_dict[current_term["id"]] = current_term["name"]
    except Exception as e:
        print(f"Error parsing HPO OBO file: {e}")
    return hpo_dict


# ---------------------------------------------------------------------------
# LLM helper that replaces the old _query_gemini_for_api
# ---------------------------------------------------------------------------

def _query_llm_for_api(
    prompt: str,
    schema: Any,
    system_template: str,
    model_name: str = "gemini-2.5-pro",
) -> Dict[str, Any]:
    """Use the LabOS LLM helper to generate a JSON API-call specification.

    This replaces the former ``_query_gemini_for_api`` by routing through
    ``json_llm_call`` from ``labos.tools.llm``.
    """
    try:
        if schema is not None:
            schema_json = json.dumps(schema, indent=2)
            system_prompt = system_template.format(schema=schema_json)
        else:
            system_prompt = system_template

        full_prompt = f"{system_prompt}\n\nUser query: {prompt}"

        raw = json_llm_call(full_prompt, model_name=model_name)

        # json_llm_call returns parsed dict on success, or dict with "error"
        if isinstance(raw, dict) and "error" in raw:
            return {
                "success": False,
                "error": raw["error"],
                "raw_response": raw.get("raw_content", ""),
            }

        return {"success": True, "data": raw, "raw_response": json.dumps(raw)}
    except (json.JSONDecodeError, KeyError, IndexError) as e:
        return {
            "success": False,
            "error": f"Failed to parse LLM response: {e}",
            "raw_response": "",
        }
    except Exception as e:
        return {"success": False, "error": f"Error querying LLM: {e}"}


# ---------------------------------------------------------------------------
# HPO name lookup (not a tool, used by tools)
# ---------------------------------------------------------------------------

def get_hpo_names(hpo_terms: List[str]) -> List[str]:
    """Retrieve the names of given HPO terms.

    Args:
        hpo_terms: A list of HPO terms (e.g. ``['HP:0001250']``).

    Returns:
        A list of corresponding HPO term names.
    """
    hp_dict = parse_hpo_obo(os.path.join(RESOURCE_DIR, "hp.obo"))
    return [hp_dict.get(term, f"Unknown term: {term}") for term in hpo_terms]


# ---------------------------------------------------------------------------
# Generic REST helper
# ---------------------------------------------------------------------------

def _query_rest_api(
    endpoint: str,
    method: str = "GET",
    params: Optional[dict] = None,
    headers: Optional[dict] = None,
    json_data: Optional[dict] = None,
    description: Optional[str] = None,
) -> dict:
    """General helper to query REST APIs with consistent error handling."""
    if headers is None:
        headers = {"Accept": "application/json"}
    if description is None:
        description = f"{method} request to {endpoint}"

    url_error = None
    try:
        if method.upper() == "GET":
            response = requests.get(endpoint, params=params, headers=headers)
        elif method.upper() == "POST":
            response = requests.post(endpoint, params=params, headers=headers, json=json_data)
        else:
            return {"error": f"Unsupported HTTP method: {method}"}

        url_error = str(response.text)
        response.raise_for_status()

        try:
            result = response.json()
        except ValueError:
            result = {"raw_text": response.text}

        return {
            "success": True,
            "query_info": {"endpoint": endpoint, "method": method, "description": description},
            "result": result,
        }
    except requests.exceptions.RequestException as e:
        error_msg = str(e)
        response_text = ""
        if hasattr(e, "response") and e.response is not None:
            try:
                error_json = e.response.json()
                for key in ("messages", "message", "error", "detail"):
                    if key in error_json:
                        val = error_json[key]
                        error_msg = "; ".join(val) if isinstance(val, list) else str(val)
                        break
            except Exception:
                response_text = e.response.text
        return {
            "success": False,
            "error": f"API error: {error_msg}",
            "query_info": {"endpoint": endpoint, "method": method, "description": description},
            "response_url_error": url_error,
            "response_text": response_text,
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Error: {e}",
            "query_info": {"endpoint": endpoint, "method": method, "description": description},
        }


# ---------------------------------------------------------------------------
# NCBI database query core
# ---------------------------------------------------------------------------

def _query_ncbi_database(
    database: str,
    search_term: str,
    result_formatter=None,
    max_results: int = 3,
) -> Dict[str, Any]:
    """Core function to query NCBI databases using eutils."""
    esearch_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
    esearch_params = {
        "db": database,
        "term": search_term,
        "retmode": "json",
        "retmax": 100,
        "usehistory": "y",
    }

    search_response = _query_rest_api(
        endpoint=esearch_url, method="GET", params=esearch_params, description="NCBI ESearch API query"
    )
    if not search_response["success"]:
        return search_response

    search_data = search_response["result"]

    if "esearchresult" in search_data and int(search_data["esearchresult"]["count"]) > 0:
        webenv = search_data["esearchresult"].get("webenv", "")
        query_key = search_data["esearchresult"].get("querykey", "")

        esummary_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi"
        if webenv and query_key:
            esummary_params = {
                "db": database,
                "query_key": query_key,
                "WebEnv": webenv,
                "retmode": "json",
                "retmax": max_results,
            }
        else:
            id_list = search_data["esearchresult"]["idlist"][:max_results]
            esummary_params = {"db": database, "id": ",".join(id_list), "retmode": "json"}

        details_response = _query_rest_api(
            endpoint=esummary_url, method="GET", params=esummary_params, description="NCBI ESummary API query"
        )
        if not details_response["success"]:
            return details_response

        results = details_response["result"]
        formatted_results = result_formatter(results) if result_formatter else results

        return {
            "database": database,
            "query_interpretation": search_term,
            "total_results": int(search_data["esearchresult"]["count"]),
            "formatted_results": formatted_results,
        }
    else:
        return {
            "database": database,
            "query_interpretation": search_term,
            "total_results": 0,
            "formatted_results": [],
        }


# ---------------------------------------------------------------------------
# Result formatter
# ---------------------------------------------------------------------------

def _format_query_results(result: Any, options: Optional[dict] = None) -> Any:
    """A general-purpose formatter to reduce output size."""

    def _format_value(value, depth, opts):
        if depth >= opts["max_depth"] and isinstance(value, (dict, list)):
            if isinstance(value, dict):
                return {"_summary": f"Nested dict with {len(value)} keys", "_keys": list(value.keys())[:opts["max_items"]]}
            return _summarize_list(value, opts)
        if isinstance(value, dict):
            return _format_dict(value, depth, opts)
        if isinstance(value, list):
            return _format_list(value, depth, opts)
        if isinstance(value, str) and len(value) > opts["truncate_strings"]:
            return value[: opts["truncate_strings"]] + "... (truncated)"
        return value

    def _format_dict(d, depth, opts):
        result_d: dict = {}
        keys = list(d.keys())
        if depth == 0 and opts["include_keys"]:
            keys = [k for k in keys if k in opts["include_keys"]]
        elif depth == 0 and opts["exclude_keys"]:
            keys = [k for k in keys if k not in opts["exclude_keys"]]
        for key in keys:
            result_d[key] = _format_value(d[key], depth + 1, opts)
        return result_d

    def _format_list(lst, depth, opts):
        if opts["summarize_lists"] and len(lst) > opts["max_items"]:
            return _summarize_list(lst, opts)
        out: list = []
        for i, item in enumerate(lst):
            if i >= opts["max_items"]:
                out.append(f"... {len(lst) - opts['max_items']} more items (omitted)")
                break
            out.append(_format_value(item, depth + 1, opts))
        return out

    def _summarize_list(lst, opts):
        if not lst:
            return []
        sample = lst[: min(3, len(lst))]
        sample_fmt = [_format_value(item, opts["max_depth"], opts) for item in sample]
        if lst:
            item_type = type(lst[0]).__name__
            homogeneous = all(isinstance(item, type(lst[0])) for item in lst)
            type_info = f"all {item_type}" if homogeneous else "mixed types"
        else:
            type_info = "empty"
        return {"_summary": f"List with {len(lst)} items ({type_info})", "_sample": sample_fmt}

    default_options = {
        "max_items": 5,
        "max_depth": 20,
        "include_keys": None,
        "exclude_keys": ["raw_response", "debug_info", "request_details"],
        "summarize_lists": True,
        "truncate_strings": 100,
    }
    if options is None:
        options = {}
    for k, v in default_options.items():
        options.setdefault(k, v)

    return _format_value(result, 0, options)


# ===================================================================
# @tool functions -- biomedical database queries
# ===================================================================


@tool
def query_uniprot(prompt: str = None, endpoint: str = None, max_results: int = 5) -> dict:
    """
    Query the UniProt REST API using either natural language or a direct endpoint.

    Args:
        prompt: Natural language query about proteins (e.g., "Find information about human insulin")
        endpoint: Full or partial UniProt API endpoint URL to query directly
        max_results: Maximum number of results to return

    Returns:
        Dictionary containing the query information and the UniProt API results

    Examples:
        - Natural language: query_uniprot(prompt="Find information about human insulin protein")
        - Direct endpoint: query_uniprot(endpoint="https://rest.uniprot.org/uniprotkb/P01308")
    """
    base_url = "https://rest.uniprot.org"

    if prompt is None and endpoint is None:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "uniprot.pkl")
        with open(schema_path, "rb") as f:
            uniprot_schema = pickle.load(f)

        system_template = """
        You are a protein biology expert specialized in using the UniProt REST API.

        Based on the user's natural language request, determine the appropriate UniProt REST API endpoint and parameters.

        UNIPROT REST API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "full_url": The complete URL to query (including base URL, dataset, endpoint type, and parameters)
        2. "description": A brief description of what the query is doing

        SPECIAL NOTES:
        - Base URL is "https://rest.uniprot.org"
        - Search in reviewed (Swiss-Prot) entries first before using non-reviewed (TrEMBL) entries
        - Assume organism is human unless otherwise specified. Human taxonomy ID is 9606
        - Use gene_exact: for exact gene name searches
        - Use specific query fields like accession:, gene:, organism_id: in search queries
        - Use quotes for terms with spaces: organism_name:"Homo sapiens"

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=uniprot_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("full_url", "")
        description = query_info.get("description", "")
        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
    else:
        if endpoint.startswith("/"):
            endpoint = f"{base_url}{endpoint}"
        elif not endpoint.startswith("http"):
            endpoint = f"{base_url}/{endpoint.lstrip('/')}"
        description = "Direct query to provided endpoint"

    return _query_rest_api(endpoint=endpoint, method="GET", description=description)


@tool
def query_alphafold(
    uniprot_id: str,
    endpoint: str = "prediction",
    residue_range: str = None,
    download: bool = False,
    output_dir: str = None,
    file_format: str = "pdb",
    model_version: str = "v4",
    model_number: int = 1,
) -> dict:
    """
    Query the AlphaFold Database API for protein structure predictions.

    Args:
        uniprot_id: UniProt accession ID (e.g., "P12345")
        endpoint: Specific AlphaFold API endpoint to query: "prediction", "summary", or "annotations"
        residue_range: Specific residue range in format "start-end" (e.g., "1-100")
        download: Whether to download structure files
        output_dir: Directory to save downloaded files (default: current directory)
        file_format: Format of the structure file to download - "pdb" or "cif"
        model_version: AlphaFold model version - "v4" (latest) or "v3", "v2", "v1"
        model_number: Model number (1-5, with 1 being the highest confidence model)

    Returns:
        Dictionary containing both the query information and the AlphaFold results
    """
    base_url = "https://alphafold.ebi.ac.uk/api"

    if not uniprot_id:
        return {"error": "UniProt ID is required"}

    valid_endpoints = ["prediction", "summary", "annotations"]
    if endpoint not in valid_endpoints:
        return {"error": f"Invalid endpoint. Must be one of: {', '.join(valid_endpoints)}"}

    if endpoint == "prediction":
        url = f"{base_url}/prediction/{uniprot_id}"
    elif endpoint == "summary":
        url = f"{base_url}/uniprot/summary/{uniprot_id}.json"
    elif endpoint == "annotations":
        url = f"{base_url}/annotations/{uniprot_id}/{residue_range}" if residue_range else f"{base_url}/annotations/{uniprot_id}"

    try:
        response = requests.get(url)
        response.raise_for_status()
        result = response.json()

        download_info = None
        if download:
            if not output_dir:
                output_dir = "."
            os.makedirs(output_dir, exist_ok=True)
            file_ext = file_format.lower()
            filename = f"AF-{uniprot_id}-F{model_number}-model_{model_version}.{file_ext}"
            file_path = os.path.join(output_dir, filename)
            download_url = f"https://alphafold.ebi.ac.uk/files/{filename}"
            download_response = requests.get(download_url)
            if download_response.status_code == 200:
                with open(file_path, "wb") as f:
                    f.write(download_response.content)
                download_info = {"success": True, "file_path": file_path, "url": download_url}
            else:
                download_info = {"success": False, "error": f"Failed to download file (status code: {download_response.status_code})", "url": download_url}

        response_data: Dict[str, Any] = {
            "query_info": {"uniprot_id": uniprot_id, "endpoint": endpoint, "residue_range": residue_range, "url": url},
            "result": result,
        }
        if download_info:
            response_data["download"] = download_info
        return response_data

    except requests.exceptions.RequestException as e:
        error_msg = str(e)
        response_text = ""
        if hasattr(e, "response") and e.response is not None:
            try:
                error_json = e.response.json()
                if "message" in error_json:
                    error_msg = error_json["message"]
            except Exception:
                response_text = e.response.text
        return {"error": f"AlphaFold API error: {error_msg}", "query_info": {"uniprot_id": uniprot_id, "endpoint": endpoint, "residue_range": residue_range, "url": url}, "response_text": response_text}
    except Exception as e:
        return {"error": f"Error: {e}", "query_info": {"uniprot_id": uniprot_id, "endpoint": endpoint, "residue_range": residue_range}}


@tool
def query_interpro(prompt: str = None, endpoint: str = None, max_results: int = 3) -> dict:
    """
    Query the InterPro REST API using natural language or a direct endpoint.

    Args:
        prompt: Natural language query about protein domains or families
        endpoint: Direct endpoint path or full URL (e.g., "/entry/interpro/IPR023411")
        max_results: Maximum number of results to return per page

    Returns:
        Dictionary containing both the query information and the InterPro API results
    """
    base_url = "https://www.ebi.ac.uk/interpro/api"

    if prompt is None and endpoint is None:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "interpro.pkl")
        with open(schema_path, "rb") as f:
            interpro_schema = pickle.load(f)

        system_template = """
        You are a protein domain expert specialized in using the InterPro REST API.

        Based on the user's natural language request, determine the appropriate InterPro REST API endpoint.

        INTERPRO REST API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "full_url": The complete URL to query (including the base URL "https://www.ebi.ac.uk/interpro/api")
        2. "description": A brief description of what the query is doing

        SPECIAL NOTES:
        - Path components for data types: entry, protein, structure, set, taxonomy, proteome
        - Common sources: interpro, pfam, cdd, uniprot, pdb
        - Protein subtypes can be "reviewed" or "unreviewed"
        - For specific entries, use lowercase accessions (e.g., "ipr000001" instead of "IPR000001")
        - Endpoints can be hierarchical like "/entry/interpro/protein/uniprot/P04637"

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=interpro_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("full_url", "")
        description = query_info.get("description", "")
        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
    else:
        if endpoint.startswith("/"):
            endpoint = f"{base_url}{endpoint}"
        elif not endpoint.startswith("http"):
            endpoint = f"{base_url}/{endpoint.lstrip('/')}"
        description = "Direct query to provided endpoint"

    params = {"page": 1, "page_size": max_results}
    return _query_rest_api(endpoint=endpoint, method="GET", params=params, description=description)


@tool
def query_pdb(prompt: str = None, query: dict = None, max_results: int = 3) -> dict:
    """
    Query the RCSB PDB database using natural language or a direct structured query.

    Args:
        prompt: Natural language query about protein structures
        query: Direct structured query in RCSB Search API format (overrides prompt)
        max_results: Maximum number of results to return

    Returns:
        Dictionary containing the structured query, search results, and identifiers
    """
    return_type = "entry"
    search_service = "full_text"

    if prompt and not query:
        schema_path = os.path.join(SCHEMA_DB_PATH, "pdb.pkl")
        with open(schema_path, "rb") as f:
            schema = pickle.load(f)

        system_template = """
        You are a structural biology expert that creates precise RCSB PDB Search API queries based on natural language requests.

        SEARCH API SCHEMA:
        {schema}

        IMPORTANT GUIDELINES:
        1. Choose the appropriate search_service based on the query:
           - Use "text" for attribute-specific searches (REQUIRES attribute, operator, and value)
           - Use "full_text" for general keyword searches across multiple fields
           - Use appropriate specialized services for sequence, structure, motif searches

        2. For "text" searches, you MUST specify:
           - attribute: The specific field to search (use common_attributes from schema)
           - operator: The comparison method (exact_match, contains_words, less_or_equal, etc.)
           - value: The search term or value

        3. For "full_text" searches, only specify:
           - value: The search term(s)

        4. For combined searches, use "group" nodes with logical_operator ("and" or "or")

        5. Always specify the appropriate return_type based on what the user is looking for

        Generate a well-formed Search API query JSON object. Return ONLY the JSON with no additional explanation.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=schema, system_template=system_template)
        if not llm_result["success"]:
            return {"error": llm_result["error"], "llm_response": llm_result.get("raw_response", "No response")}

        query_json = llm_result["data"]
    else:
        query_json = query if query else {
            "query": {"type": "terminal", "service": search_service, "parameters": {"value": prompt}},
            "return_type": return_type,
        }

    if "return_type" not in query_json:
        query_json["return_type"] = return_type
    if "request_options" not in query_json:
        query_json["request_options"] = {}
    if "return_all_hits" in query_json["request_options"] and query_json["request_options"]["return_all_hits"]:
        query_json["request_options"]["return_all_hits"] = False
    if "paginate" not in query_json["request_options"]:
        query_json["request_options"]["paginate"] = {"start": 0, "rows": max_results}

    search_url = "https://search.rcsb.org/rcsbsearch/v2/query"
    return _query_rest_api(endpoint=search_url, method="POST", json_data=query_json, description="PDB Search API query")


@tool
def query_pdb_identifiers(identifiers: List[str], return_type: str = "entry", download: bool = False, attributes: List[str] = None) -> dict:
    """
    Retrieve detailed data and/or download files for PDB identifiers.

    Args:
        identifiers: List of PDB identifiers (from query_pdb)
        return_type: Type of results: "entry", "assembly", "polymer_entity", etc.
        download: Whether to download PDB structure files
        attributes: List of specific attributes to retrieve

    Returns:
        Dictionary containing the detailed data and file paths if downloaded
    """
    if not identifiers:
        return {"error": "No identifiers provided"}

    try:
        detailed_results = []
        for identifier in identifiers:
            try:
                if return_type == "entry":
                    data_url = f"https://data.rcsb.org/rest/v1/core/entry/{identifier}"
                elif return_type == "polymer_entity":
                    entry_id, entity_id = identifier.split("_")
                    data_url = f"https://data.rcsb.org/rest/v1/core/polymer_entity/{entry_id}/{entity_id}"
                elif return_type == "nonpolymer_entity":
                    entry_id, entity_id = identifier.split("_")
                    data_url = f"https://data.rcsb.org/rest/v1/core/nonpolymer_entity/{entry_id}/{entity_id}"
                elif return_type == "polymer_instance":
                    entry_id, asym_id = identifier.split(".")
                    data_url = f"https://data.rcsb.org/rest/v1/core/polymer_entity_instance/{entry_id}/{asym_id}"
                elif return_type == "assembly":
                    entry_id, assembly_id = identifier.split("-")
                    data_url = f"https://data.rcsb.org/rest/v1/core/assembly/{entry_id}/{assembly_id}"
                elif return_type == "mol_definition":
                    data_url = f"https://data.rcsb.org/rest/v1/core/chem_comp/{identifier}"
                else:
                    data_url = f"https://data.rcsb.org/rest/v1/core/entry/{identifier}"

                data_response = requests.get(data_url)
                data_response.raise_for_status()
                entity_data = data_response.json()

                if attributes:
                    filtered_data: dict = {}
                    for attr in attributes:
                        parts = attr.split(".")
                        current = entity_data
                        try:
                            for part in parts[:-1]:
                                current = current[part]
                            filtered_data[attr] = current[parts[-1]]
                        except (KeyError, TypeError):
                            filtered_data[attr] = None
                    entity_data = filtered_data

                detailed_results.append({"identifier": identifier, "data": entity_data})
            except Exception as e:
                detailed_results.append({"identifier": identifier, "error": str(e)})

        if download:
            for identifier in identifiers:
                if "_" in identifier or "." in identifier or "-" in identifier:
                    if "_" in identifier:
                        pdb_id = identifier.split("_")[0]
                    elif "." in identifier:
                        pdb_id = identifier.split(".")[0]
                    else:
                        pdb_id = identifier.split("-")[0]
                else:
                    pdb_id = identifier
                try:
                    pdb_url = f"https://files.rcsb.org/download/{pdb_id}.pdb"
                    pdb_response = requests.get(pdb_url)
                    if pdb_response.status_code == 200:
                        data_dir = os.path.join(os.path.dirname(__file__), "data", "pdb")
                        os.makedirs(data_dir, exist_ok=True)
                        pdb_file_path = os.path.join(data_dir, f"{pdb_id}.pdb")
                        with open(pdb_file_path, "wb") as pdb_file:
                            pdb_file.write(pdb_response.content)
                        for r in detailed_results:
                            if r["identifier"] == identifier or r["identifier"].startswith(pdb_id):
                                r["pdb_file_path"] = pdb_file_path
                except Exception as e:
                    for r in detailed_results:
                        if r["identifier"] == identifier or r["identifier"].startswith(pdb_id):
                            r["download_error"] = str(e)

        return {"detailed_results": detailed_results}
    except Exception as e:
        return {"error": f"Error retrieving PDB details: {e}"}


@tool
def query_kegg(prompt: str, endpoint: str = None, verbose: bool = True) -> dict:
    """
    Take a natural language prompt and convert it to a structured KEGG API query.

    Args:
        prompt: Natural language query about KEGG data (e.g., "Find human pathways related to glycolysis")
        endpoint: Direct KEGG API endpoint to query
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing both the structured query and the KEGG results
    """
    base_url = "https://rest.kegg.jp"

    if not prompt and not endpoint:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "kegg.pkl")
        with open(schema_path, "rb") as f:
            kegg_schema = pickle.load(f)

        system_template = """
        You are a bioinformatics expert that helps convert natural language queries into KEGG API requests.

        Based on the user's natural language request, you will generate a structured query for the KEGG API.

        The KEGG API has the following general form:
        https://rest.kegg.jp/<operation>/<argument>[/<argument2>[/<argument3> ...]]

        Where <operation> can be one of: info, list, find, get, conv, link, ddi

        Here is the schema of available operations, databases, and other details:
        {schema}

        Output only a JSON object with the following fields:
        1. "full_url": The complete URL to query (including the base URL "https://rest.kegg.jp")
        2. "description": A brief description of what the query is doing

        IMPORTANT: Your response must ONLY contain a JSON object with the required fields.

        EXAMPLES OF CORRECT OUTPUTS:
        - For "Find information about glycolysis pathway": {{"full_url": "https://rest.kegg.jp/info/pathway/hsa00010", "description": "Finding information about the glycolysis pathway"}}
        - For "Get information about the human BRCA1 gene": {{"full_url": "https://rest.kegg.jp/get/hsa:672", "description": "Retrieving information about BRCA1 gene in human"}}
        - For "List all human pathways": {{"full_url": "https://rest.kegg.jp/list/pathway/hsa", "description": "Listing all human-specific pathways"}}
        - For "Convert NCBI gene ID 672 to KEGG ID": {{"full_url": "https://rest.kegg.jp/conv/genes/ncbi-geneid:672", "description": "Converting NCBI Gene ID 672 to KEGG gene identifier"}}
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=kegg_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info["full_url"]
        description = query_info["description"]

        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}

    if endpoint:
        if endpoint.startswith("/"):
            endpoint = f"{base_url}{endpoint}"
        elif not endpoint.startswith("http"):
            endpoint = f"{base_url}/{endpoint.lstrip('/')}"
        description = "Direct query to KEGG API"

    api_result = _query_rest_api(endpoint=endpoint, method="GET", description=description)

    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        return _format_query_results(api_result["result"])
    return api_result


@tool
def query_stringdb(prompt: str = None, endpoint: str = None, download_image: bool = False, output_dir: str = None, verbose: bool = True) -> dict:
    """
    Query the STRING protein interaction database using natural language or direct endpoint.

    Args:
        prompt: Natural language query about protein interactions
        endpoint: Full URL to query directly (overrides prompt)
        download_image: Whether to download image results
        output_dir: Directory to save downloaded files
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing the query results or error information
    """
    base_url = "https://version-12-0.string-db.org/api"

    if prompt is None and endpoint is None:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "stringdb.pkl")
        with open(schema_path, "rb") as f:
            stringdb_schema = pickle.load(f)

        system_template = """
        You are a protein interaction expert specialized in using the STRING database API.

        Based on the user's natural language request, determine the appropriate STRING API endpoint and parameters.

        STRING API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "full_url": The complete URL to query (including all parameters)
        2. "description": A brief description of what the query is doing
        3. "output_format": The format of the output (json, tsv, image, svg)

        SPECIAL NOTES:
        - Common species IDs: 9606 (human), 10090 (mouse), 7227 (fruit fly), 4932 (yeast)
        - For protein identifiers, use either gene names (e.g., "BRCA1") or UniProt IDs (e.g., "P38398")
        - The "required_score" parameter accepts values from 0 to 1000 (higher means more stringent)
        - Add "caller_identity=labos_api" as a parameter

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=stringdb_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("full_url", "")
        description = query_info.get("description", "")
        output_format = query_info.get("output_format", "json")

        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
    else:
        if endpoint.startswith("/"):
            endpoint = f"{base_url}{endpoint}"
        elif not endpoint.startswith("http"):
            endpoint = f"{base_url}/{endpoint.lstrip('/')}"
        description = "Direct query to STRING API"
        output_format = "json"
        if "image" in endpoint or "svg" in endpoint:
            output_format = "image"

    is_image = output_format in ["image", "highres_image", "svg"]

    if is_image:
        if download_image:
            try:
                response = requests.get(endpoint, stream=True)
                response.raise_for_status()
                if not output_dir:
                    output_dir = "."
                os.makedirs(output_dir, exist_ok=True)
                endpoint_parts = endpoint.split("/")
                filename = f"string_{endpoint_parts[-2]}_{int(time.time())}.{output_format}"
                file_path = os.path.join(output_dir, filename)
                with open(file_path, "wb") as f:
                    for chunk in response.iter_content(chunk_size=1024):
                        if chunk:
                            f.write(chunk)
                return {
                    "success": True,
                    "query_info": {"endpoint": endpoint, "description": description, "output_format": output_format},
                    "result": {"image_saved": True, "file_path": file_path, "content_type": response.headers.get("Content-Type")},
                }
            except Exception as e:
                return {"success": False, "error": f"Error downloading image: {e}", "query_info": {"endpoint": endpoint, "description": description}}
        else:
            return {
                "success": True,
                "query_info": {"endpoint": endpoint, "description": description, "output_format": output_format},
                "result": {"image_available": True, "download_url": endpoint, "note": "Set download_image=True to save the image"},
            }

    api_result = _query_rest_api(endpoint=endpoint, method="GET", description=description)
    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        return _format_query_results(api_result["result"])
    return api_result


@tool
def query_paleobiology(prompt: str = None, endpoint: str = None, verbose: bool = True) -> dict:
    """
    Query the Paleobiology Database (PBDB) API using natural language or a direct endpoint.

    Args:
        prompt: Natural language query about fossil records
        endpoint: API endpoint name or full URL
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing the query results or error information
    """
    base_url = "https://paleobiodb.org/data1.2"

    if prompt is None and endpoint is None:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "paleobiology.pkl")
        with open(schema_path, "rb") as f:
            pbdb_schema = pickle.load(f)

        system_template = """
        You are a paleobiology expert specialized in using the Paleobiology Database (PBDB) API.

        Based on the user's natural language request, determine the appropriate PBDB API endpoint and parameters.

        PBDB API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "full_url": The complete URL to query (including the base URL "https://paleobiodb.org/data1.2" and format extension)
        2. "description": A brief description of what the query is doing

        SPECIAL NOTES:
        - For taxonomic queries, be specific about taxonomic ranks and names
        - For geographic queries, use standard country/continent names or coordinate bounding boxes
        - For time interval queries, use standard geological time names (e.g., "Cretaceous", "Maastrichtian")
        - Use appropriate format extension (.json, .txt, .csv, .tsv) based on the query
        - If appropriate, use "vocab=pbdb" (default) or "vocab=com" (compact) parameter in the URL
        - For detailed occurrence data, include "show=paleoloc,phylo" in the parameters

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=pbdb_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("full_url", "")
        description = query_info.get("description", "")

        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
    else:
        if not endpoint.startswith("http"):
            endpoint = f"{base_url}/{'/' if not endpoint.startswith('/') else ''}{endpoint}"
        description = "Direct query to PBDB API"

    is_image = endpoint.endswith(".png")
    if is_image:
        try:
            response = requests.get(endpoint)
            response.raise_for_status()
            return {
                "success": True,
                "query_info": {"endpoint": endpoint, "description": description, "format": "png"},
                "result": {"content_type": response.headers.get("Content-Type"), "size_bytes": len(response.content), "note": "Binary image data not included in response"},
            }
        except Exception as e:
            return {"success": False, "error": f"Error retrieving image: {e}", "query_info": {"endpoint": endpoint, "description": description}}

    api_result = _query_rest_api(endpoint=endpoint, method="GET", description=description)
    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        return _format_query_results(api_result["result"])
    return api_result


@tool
def query_jaspar(prompt: str = None, endpoint: str = None, verbose: bool = True) -> dict:
    """
    Query the JASPAR REST API using natural language or a direct endpoint.

    Args:
        prompt: Natural language query about transcription factor binding profiles
        endpoint: API endpoint path (e.g., "/matrix/MA0002.2/") or full URL
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing the query results or error information
    """
    base_url = "https://jaspar.elixir.no/api/v1"

    if prompt is None and endpoint is None:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "jaspar.pkl")
        with open(schema_path, "rb") as f:
            jaspar_schema = pickle.load(f)

        system_template = """
        You are a transcription factor binding site expert specialized in using the JASPAR REST API.

        Based on the user's natural language request, determine the appropriate JASPAR REST API endpoint and parameters.

        JASPAR REST API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "full_url": The complete URL to query (including the base URL "https://jaspar.elixir.no/api/v1" and any parameters)
        2. "description": A brief description of what the query is doing

        SPECIAL NOTES:
        - Common taxonomic groups include: vertebrates, plants, fungi, insects, nematodes, urochordates
        - Common collections include: CORE, UNVALIDATED, PENDING, etc.
        - Matrix IDs follow the format MA####.# (e.g., MA0002.2)
        - For inferring matrices from sequences, provide the protein sequence directly in the path

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=jaspar_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("full_url", "")
        description = query_info.get("description", "")
        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
    else:
        if not endpoint.startswith("http"):
            if not endpoint.startswith("/"):
                endpoint = "/" + endpoint
            if not endpoint.endswith("/"):
                endpoint = endpoint + "/"
            endpoint = f"{base_url}{endpoint}"
        description = "Direct query to JASPAR API"

    api_result = _query_rest_api(endpoint=endpoint, method="GET", description=description)
    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        return _format_query_results(api_result["result"])
    return api_result


@tool
def query_worms(prompt: str = None, endpoint: str = None, verbose: bool = True) -> dict:
    """
    Query the World Register of Marine Species (WoRMS) REST API using natural language or a direct endpoint.

    Args:
        prompt: Natural language query about marine species
        endpoint: Full URL or endpoint specification
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing the query results or error information
    """
    base_url = "https://www.marinespecies.org/rest"

    if prompt is None and endpoint is None:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "worms.pkl")
        with open(schema_path, "rb") as f:
            worms_schema = pickle.load(f)

        system_template = """
        You are a marine biology expert specialized in using the World Register of Marine Species (WoRMS) API.

        Based on the user's natural language request, determine the appropriate WoRMS API endpoint and parameters.

        WORMS API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "full_url": The complete URL to query (including the base URL "https://www.marinespecies.org/rest" and any path/query parameters)
        2. "description": A brief description of what the query is doing

        SPECIAL NOTES:
        - For taxonomic searches, be precise with scientific names and use proper capitalization
        - For fuzzy matching, include "fuzzy=true" in the URL query parameters
        - When searching by name, prefer "AphiaRecordByName" for exact matches and "AphiaRecordsByName" for broader results
        - AphiaID is the main identifier in WoRMS (e.g., Blue Whale is 137087)
        - For multiple IDs or names, use the appropriate POST endpoint

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=worms_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("full_url", "")
        description = query_info.get("description", "")
        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
    else:
        if not endpoint.startswith("http"):
            if not endpoint.startswith("/"):
                endpoint = f"{base_url}/{endpoint}"
            else:
                endpoint = f"{base_url}{endpoint}"
        description = "Direct query to WoRMS API"

    api_result = _query_rest_api(endpoint=endpoint, method="GET", description=description)
    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        return _format_query_results(api_result["result"])
    return api_result


@tool
def query_cbioportal(prompt: str = None, endpoint: str = None, verbose: bool = True) -> dict:
    """
    Query the cBioPortal REST API using natural language or a direct endpoint.

    Args:
        prompt: Natural language query about cancer genomics data
        endpoint: API endpoint path (e.g., "/studies/brca_tcga/patients") or full URL
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing the query results or error information
    """
    base_url = "https://www.cbioportal.org/api"

    if prompt is None and endpoint is None:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "cbioportal.pkl")
        with open(schema_path, "rb") as f:
            cbioportal_schema = pickle.load(f)

        system_template = """
        You are a cancer genomics expert specialized in using the cBioPortal REST API.

        Based on the user's natural language request, determine the appropriate cBioPortal REST API endpoint and parameters.

        CBIOPORTAL REST API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "full_url": The complete URL to query (including the base URL "https://www.cbioportal.org/api" and any parameters)
        2. "description": A brief description of what the query is doing

        SPECIAL NOTES:
        - For gene queries, use either Hugo symbol (e.g., "BRCA1") or Entrez ID (e.g., 672)
        - For pagination, include parameters "pageNumber" and "pageSize" if needed
        - For mutation data queries, always include appropriate sample identifiers
        - Common studies include: "brca_tcga" (breast cancer), "gbm_tcga" (glioblastoma), "luad_tcga" (lung adenocarcinoma)
        - For molecular profiles, common IDs follow pattern: "[study]_[data_type]" (e.g., "brca_tcga_mutations")
        - Consider including "projection=DETAILED" for more comprehensive results when appropriate

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=cbioportal_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("full_url", "")
        description = query_info.get("description", "")
        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
    else:
        if not endpoint.startswith("http"):
            if not endpoint.startswith("/"):
                endpoint = "/" + endpoint
            endpoint = f"{base_url}{endpoint}"
        description = "Direct query to cBioPortal API"

    api_result = _query_rest_api(endpoint=endpoint, method="GET", description=description)
    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        return _format_query_results(api_result["result"])
    return api_result


@tool
def query_clinvar(prompt: str = None, search_term: str = None, max_results: int = 3) -> dict:
    """
    Take a natural language prompt and convert it to a structured ClinVar query.

    Args:
        prompt: Natural language query about genetic variants (e.g., "Find pathogenic BRCA1 variants")
        search_term: Direct search term for ClinVar
        max_results: Maximum number of results to return

    Returns:
        Dictionary containing both the structured query and the ClinVar results
    """
    if not prompt and not search_term:
        return {"error": "Either a prompt or a search_term must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "clinvar.pkl")
        with open(schema_path, "rb") as f:
            clinvar_schema = pickle.load(f)

        system_prompt_template = """
        You are a genetics research assistant that helps convert natural language queries into structured ClinVar search queries.

        Based on the user's natural language request, you will generate a structured search for the ClinVar database.

        Output only a JSON object with the following fields:
        1. "search_term": The exact search query to use with the ClinVar API

        IMPORTANT: Your response must ONLY contain a JSON object with the search term field.

        Your "search_term" MUST strictly follow these ClinVar search syntax rules/tags:

        {schema}

        For combining terms: Use AND, OR, NOT (must be capitalized)
        For complex logic: Use parentheses
        For terms with multiple words: use double quotes escaped with a backslash or underscore (e.g. breast_cancer[dis] or \\"breast cancer\\"[dis])
        Example: "BRCA1[gene] AND (pathogenic[clinsig] OR likely_pathogenic[clinsig])"

        EXAMPLES OF CORRECT QUERIES:
        - For "pathogenic BRCA1 variants": "BRCA1[gene] AND clinsig_pathogenic[prop]"
        - For "Specific RS": "rs6025[rsid]"
        - For "Combined search with multiple criteria": "BRCA1[gene] AND origin_germline[prop]"
        - For "Find variants in a specific genomic region": "17[chr] AND 43000000:44000000[chrpos37]"
        - If query asks for pathogenicity of a variant, it's asking for all possible germline classifications of the variant, so just [gene] AND [variant] is needed
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=clinvar_schema, system_template=system_prompt_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        search_term = query_info.get("search_term", "")

        if not search_term:
            return {"error": "Failed to generate a valid search term from the prompt", "llm_response": llm_result.get("raw_response", "No response")}

    return _query_ncbi_database(database="clinvar", search_term=search_term, max_results=max_results)


@tool
def query_geo(prompt: str = None, search_term: str = None, max_results: int = 3) -> dict:
    """
    Query the NCBI Gene Expression Omnibus (GEO) using natural language or a direct search term.

    Args:
        prompt: Natural language query about RNA-seq, microarray, or other expression data
        search_term: Direct search term in GEO syntax
        max_results: Maximum number of results to return

    Returns:
        Dictionary containing the query results or error information
    """
    if not prompt and not search_term:
        return {"error": "Either a prompt or a search term must be provided"}

    database = "gds"

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "geo.pkl")
        with open(schema_path, "rb") as f:
            geo_schema = pickle.load(f)

        system_template = """
        You are a bioinformatics research assistant that helps convert natural language queries into structured GEO (Gene Expression Omnibus) search queries.

        Based on the user's natural language request, you will generate a structured search for the GEO database.

        Output only a JSON object with the following fields:
        1. "search_term": The exact search query to use with the GEO API
        2. "database": The specific GEO database to search (either "gds" for GEO DataSets or "geoprofiles" for GEO Profiles)

        IMPORTANT: Your response must ONLY contain a JSON object with the required fields.

        Your "search_term" MUST strictly follow these GEO search syntax rules/tags:

        {schema}

        For combining terms: Use AND, OR, NOT (must be capitalized)
        For complex logic: Use parentheses
        For terms with multiple words: use double quotes or underscore (e.g. "breast cancer"[Title])
        Date ranges use colon format: 2015/01:2020/12[PDAT]

        Choose the appropriate database based on the user's query:
        - gds: GEO DataSets (contains Series, Datasets, Platforms, Samples metadata)
        - geoprofiles: GEO Profiles (contains gene expression data)

        If database isn't clearly specified, default to "gds" as it contains most common experiment metadata.

        EXAMPLES OF CORRECT OUTPUTS:
        - For "RNA-seq data in breast cancer": {{"search_term": "RNA-seq AND breast cancer AND gse[ETYP]", "database": "gds"}}
        - For "Mouse microarray data from 2020": {{"search_term": "Mus musculus[ORGN] AND 2020[PDAT] AND microarray AND gse[ETYP]", "database": "gds"}}
        - For "Expression profiles of TP53 in lung cancer": {{"search_term": "TP53[Gene Symbol] AND lung cancer", "database": "geoprofiles"}}
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=geo_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        search_term = query_info.get("search_term", "")
        database = query_info.get("database", "gds")

        if not search_term:
            return {"error": "Failed to generate a valid search term from the prompt", "llm_response": llm_result.get("raw_response", "No response")}

    return _query_ncbi_database(database=database, search_term=search_term, max_results=max_results)


@tool
def query_dbsnp(prompt: str = None, search_term: str = None, max_results: int = 3) -> dict:
    """
    Query the NCBI dbSNP database using natural language or a direct search term.

    Args:
        prompt: Natural language query about genetic variants/SNPs
        search_term: Direct search term in dbSNP syntax
        max_results: Maximum number of results to return

    Returns:
        Dictionary containing the query results or error information
    """
    if not prompt and not search_term:
        return {"error": "Either a prompt or a search term must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "dbsnp.pkl")
        with open(schema_path, "rb") as f:
            dbsnp_schema = pickle.load(f)

        system_template = """
        You are a genetics research assistant that helps convert natural language queries into structured dbSNP search queries.

        Based on the user's natural language request, you will generate a structured search for the dbSNP database.

        Output only a JSON object with the following fields:
        1. "search_term": The exact search query to use with the dbSNP API

        IMPORTANT: Your response must ONLY contain a JSON object with the search term field.

        Your "search_term" MUST strictly follow these dbSNP search syntax rules/tags:

        {schema}

        For combining terms: Use AND, OR, NOT (must be capitalized)
        For complex logic: Use parentheses
        For terms with multiple words: use double quotes (e.g. "breast cancer"[Disease Name])

        EXAMPLES OF CORRECT QUERIES:
        - For "pathogenic variants in BRCA1": "BRCA1[Gene Name] AND pathogenic[Clinical Significance]"
        - For "specific SNP rs6025": "rs6025[rs]"
        - For "SNPs in a genomic region": "17[Chromosome] AND 41196312:41277500[Base Position]"
        - For "common SNPs in EGFR": "EGFR[Gene Name] AND common[COMMON]"
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=dbsnp_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        search_term = query_info.get("search_term", "")

        if not search_term:
            return {"error": "Failed to generate a valid search term from the prompt", "llm_response": llm_result.get("raw_response", "No response")}

    return _query_ncbi_database(database="snp", search_term=search_term, max_results=max_results)


@tool
def query_ucsc(prompt: str = None, endpoint: str = None, verbose: bool = True) -> dict:
    """
    Query the UCSC Genome Browser API using natural language or a direct endpoint.

    Args:
        prompt: Natural language query about genomic data
        endpoint: Full URL or endpoint specification with parameters
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing the query results or error information
    """
    base_url = "https://api.genome.ucsc.edu"

    if prompt is None and endpoint is None:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "ucsc.pkl")
        with open(schema_path, "rb") as f:
            ucsc_schema = pickle.load(f)

        system_template = """
        You are a genomics expert specialized in using the UCSC Genome Browser API.

        Based on the user's natural language request, determine the appropriate UCSC Genome Browser API endpoint and parameters.

        UCSC GENOME BROWSER API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "full_url": The complete URL to query (including the base URL "https://api.genome.ucsc.edu" and all parameters)
        2. "description": A brief description of what the query is doing

        SPECIAL NOTES:
        - For chromosome names, always include the "chr" prefix (e.g., "chr1", "chrX", "chrM")
        - Genomic positions are 0-based (first base is position 0)
        - For "start" and "end" parameters, both must be provided together
        - The "maxItemsOutput" parameter can be used to limit the amount of data returned
        - Common genomes include: "hg38" (human), "mm39" (mouse), "danRer11" (zebrafish)
        - For sequence data, use "getData/sequence" endpoint
        - For chromosome listings, use "list/chromosomes" endpoint
        - For available genomes, use "list/ucscGenomes" endpoint

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=ucsc_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("full_url", "")
        description = query_info.get("description", "")

        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
    else:
        if not endpoint.startswith("http"):
            endpoint = f"{base_url}/{endpoint}"
        description = "Direct query to UCSC Genome Browser API"

    api_result = _query_rest_api(endpoint=endpoint, method="GET", description=description)
    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        return _format_query_results(api_result["result"])
    return api_result


@tool
def query_ensembl(prompt: str = None, endpoint: str = None, verbose: bool = True) -> dict:
    """
    Query the Ensembl REST API using natural language or a direct endpoint.

    Args:
        prompt: Natural language query about genomic data
        endpoint: Direct API endpoint to query (e.g., "lookup/symbol/human/BRCA2") or full URL
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing the query results or error information
    """
    base_url = "https://rest.ensembl.org"

    if not prompt and not endpoint:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "ensembl.pkl")
        with open(schema_path, "rb") as f:
            ensembl_schema = pickle.load(f)

        system_template = """
        You are a genomics and bioinformatics expert specialized in using the Ensembl REST API.

        Based on the user's natural language request, determine the appropriate Ensembl REST API endpoint and parameters.

        ENSEMBL REST API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "endpoint": The API endpoint to query (e.g., "lookup/symbol/homo_sapiens/BRCA2")
        2. "params": An object containing query parameters specific to the endpoint
        3. "description": A brief description of what the query is doing

        SPECIAL NOTES:
        - Chromosome region queries have a maximum length of 4900000 bp inclusive, so bp of start and end should be 4900000 bp apart. If the user's query exceeds this limit, Ensembl will return an error.
        - For symbol lookups, the format is "lookup/symbol/[species]/[symbol]"
        - To find the coordinates of a band on a chromosome, use /info/assembly/homo_sapiens/[chromosome] with parameters "band":1
        - To find the overlapping genes of a genomic region, use /overlap/region/homo_sapiens/[chromosome]:[start]-[end]
        - For sequence queries, specify the sequence type in parameters (genomic, cdna, cds, protein)
        - For converting rsID to hg38 genomic coordinates, use the "GET id/variation/[species]/[rsid]" endpoint
        - Many endpoints support "content-type" parameter for format specification (application/json, text/xml)

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=ensembl_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("endpoint", "")
        params = query_info.get("params", {})
        description = query_info.get("description", "")

        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
    else:
        if endpoint.startswith("http"):
            if endpoint.startswith(base_url):
                endpoint = endpoint[len(base_url):].lstrip("/")
        params = {}
        description = "Direct query to Ensembl API"

    if endpoint.startswith("/"):
        endpoint = endpoint[1:]

    headers = {"Content-Type": "application/json", "Accept": "application/json"}
    url = f"{base_url}/{endpoint}"

    api_result = _query_rest_api(endpoint=url, method="GET", params=params, headers=headers, description=description)
    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        return _format_query_results(api_result["result"])
    return api_result


@tool
def query_opentarget_genetics(prompt: str = None, query: str = None, variables: dict = None, verbose: bool = True) -> dict:
    """
    Query the OpenTargets Genetics API using natural language or a direct GraphQL query.

    Args:
        prompt: Natural language query about genetic targets and variants
        query: Direct GraphQL query string
        variables: Variables for the GraphQL query
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing the query results or error information
    """
    OPENTARGETS_URL = "https://api.genetics.opentargets.org/graphql"

    if prompt is None and query is None:
        return {"error": "Either a prompt or a GraphQL query must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "opentarget_genetics.pkl")
        with open(schema_path, "rb") as f:
            opentarget_schema = pickle.load(f)

        system_template = """
        You are an expert in translating natural language requests into GraphQL queries for the OpenTargets Genetics API.

        Here is a schema of the main types and queries available in the OpenTargets Genetics API:
        {schema}

        Translate the user's natural language request into a valid GraphQL query for this API.
        Return only a JSON object with two fields:
        1. "query": The complete GraphQL query string
        2. "variables": A JSON object containing the variables needed for the query

        SPECIAL NOTES:
        - Variant IDs are typically in the format 'chromosome_position_ref_alt' (e.g., '1_154453788_C_T')
        - For L2G (locus-to-gene) queries, you need both a variant ID and a study ID
        - The API can provide variant information, QTLs, PheWAS results, pathogenicity scores, etc.
        - For mutations by gene, use the approved gene symbol (e.g., "BRCA1")
        - Always escape special characters, including quotes, in the query string

        Return ONLY the JSON object with no additional text or explanations.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=opentarget_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        query = query_info.get("query", "")
        if variables is None:
            variables = query_info.get("variables", {})

        if not query:
            return {"error": "Failed to generate a valid GraphQL query from the prompt", "llm_response": llm_result.get("raw_response", "No response")}

    api_result = _query_rest_api(
        endpoint=OPENTARGETS_URL,
        method="POST",
        json_data={"query": query, "variables": variables or {}},
        headers={"Content-Type": "application/json"},
    )

    if not api_result["success"]:
        return api_result
    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        return _format_query_results(api_result["result"])
    return api_result


@tool
def query_opentarget(prompt: str = None, query: str = None, variables: dict = None, verbose: bool = False) -> dict:
    """
    Query the OpenTargets Platform API using natural language or a direct GraphQL query.

    Args:
        prompt: Natural language query about drug targets, diseases, and mechanisms
        query: Direct GraphQL query string
        variables: Variables for the GraphQL query
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing the query results or error information
    """
    OPENTARGETS_URL = "https://api.platform.opentargets.org/api/v4/graphql"

    if prompt is None and query is None:
        return {"error": "Either a prompt or a GraphQL query must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "opentarget.pkl")
        with open(schema_path, "rb") as f:
            opentarget_schema = pickle.load(f)

        system_template = """
        You are an expert in translating natural language requests into GraphQL queries for the OpenTargets Platform API.

        Here is a schema of the main types and queries available in the OpenTargets Platform API:
        {schema}

        Translate the user's natural language request into a valid GraphQL query for this API.
        Return only a JSON object with two fields:
        1. "query": The complete GraphQL query string
        2. "variables": A JSON object containing the variables needed for the query

        SPECIAL NOTES:
        - Disease IDs typically use EFO ontology (e.g., "EFO_0000249" for Alzheimer's disease)
        - Target IDs typically use Ensembl IDs (e.g., "ENSG00000197386")
        - The API can provide information about drug-target associations, disease-target associations, etc.
        - Always limit results to a reasonable number using "first" parameter (e.g., first: 10)
        - Always escape special characters, including quotes, in the query string

        Return ONLY the JSON object with no additional text or explanations.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=opentarget_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        query = query_info.get("query", "")
        if variables is None:
            variables = query_info.get("variables", {})

        if not query:
            return {"error": "Failed to generate a valid GraphQL query from the prompt", "llm_response": llm_result.get("raw_response", "No response")}

    api_result = _query_rest_api(
        endpoint=OPENTARGETS_URL,
        method="POST",
        json_data={"query": query, "variables": variables or {}},
        headers={"Content-Type": "application/json"},
        description="OpenTargets Platform GraphQL query",
    )

    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        api_result["result"] = _format_query_results(api_result["result"])
    return api_result


@tool
def query_gwas_catalog(prompt: str = None, endpoint: str = None, max_results: int = 3) -> dict:
    """
    Query the GWAS Catalog API using natural language or a direct endpoint.

    Args:
        prompt: Natural language query about GWAS data
        endpoint: Full API endpoint to query
        max_results: Maximum number of results to return

    Returns:
        Dictionary containing the query results or error information
    """
    base_url = "https://www.ebi.ac.uk/gwas/rest/api"

    if prompt is None and endpoint is None:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "gwas_catalog.pkl")
        with open(schema_path, "rb") as f:
            gwas_schema = pickle.load(f)

        system_template = """
        You are a genomics expert specialized in using the GWAS Catalog API.

        Based on the user's natural language request, determine the appropriate GWAS Catalog API endpoint and parameters.

        GWAS CATALOG API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "endpoint": The API endpoint to query (e.g., "studies", "associations")
        2. "params": An object containing query parameters specific to the endpoint
        3. "description": A brief description of what the query is doing

        SPECIAL NOTES:
        - For disease/trait searches, consider using the "EFO" identifiers when possible
        - Common endpoints include: "studies", "associations", "singleNucleotidePolymorphisms", "efoTraits"
        - For pagination, use "size" and "page" parameters
        - For filtering by p-value, use "pvalueMax" parameter
        - GWAS Catalog uses a HAL-based REST API

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=gwas_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("endpoint", "")
        params = query_info.get("params", {})
        description = query_info.get("description", "")

        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
    else:
        if endpoint is None:
            endpoint = ""
        params = {"size": max_results}
        description = f"Direct query to {endpoint}"

    if endpoint.startswith("/"):
        endpoint = endpoint[1:]

    url = f"{base_url}/{endpoint}"
    return _query_rest_api(endpoint=url, method="GET", params=params, description=description)


@tool
def query_gnomad(prompt: str = None, gene_symbol: str = None, verbose: bool = True) -> dict:
    """
    Query gnomAD for variants in a gene using natural language or direct gene symbol.

    Args:
        prompt: Natural language query about genetic variants
        gene_symbol: Gene symbol (e.g., "BRCA1")
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing the query results or error information
    """
    base_url = "https://gnomad.broadinstitute.org/api"

    if prompt is None and gene_symbol is None:
        return {"error": "Either a prompt or a gene_symbol must be provided"}

    if prompt and not gene_symbol:
        schema_path = os.path.join(SCHEMA_DB_PATH, "gnomad.pkl")
        with open(schema_path, "rb") as f:
            gnomad_schema = pickle.load(f)

        system_template = """
        You are a genomics expert specialized in using the gnomAD GraphQL API.

        Based on the user's natural language request, extract the gene symbol and relevant parameters and create the gnomAD GraphQL query.

        GnomAD GraphQL API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "query": The complete GraphQL query string

        SPECIAL NOTES:
        - The gene_symbol should be the official gene symbol (e.g., "BRCA1" not "breast cancer gene 1")
        - If no reference genome is specified, default to GRCh38
        - If no dataset is specified, default to gnomad_r4
        - Return only a single gene symbol, even if multiple are mentioned
        - Always escape special characters, including quotes, in the query string

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=gnomad_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        query_str = query_info.get("query", "")

        if not query_str:
            return {"error": "Failed to extract a valid query from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
        description = "gnomAD GraphQL query from prompt"
    else:
        schema_path = os.path.join(SCHEMA_DB_PATH, "gnomad.pkl")
        with open(schema_path, "rb") as f:
            gnomad_schema = pickle.load(f)
        description = f"Query gnomAD for variants in {gene_symbol}"
        query_str = gnomad_schema.replace("BRCA1", gene_symbol)

    api_result = _query_rest_api(
        endpoint=base_url,
        method="POST",
        json_data={"query": query_str},
        headers={"Content-Type": "application/json"},
        description=description,
    )

    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        return _format_query_results(api_result["result"])
    return api_result


@tool
def blast_sequence(sequence: str, database: str, program: str) -> Union[Dict[str, Union[str, float]], str]:
    """
    Identifies a DNA sequence using NCBI BLAST with improved error handling, timeout management, and debugging.

    Args:
        sequence: The sequence to identify. If DNA, use database: core_nt, program: blastn;
                  if protein, use database: nr, program: blastp
        database: The BLAST database to search against
        program: The BLAST program to use

    Returns:
        A dictionary containing the title, e-value, identity percentage, and coverage percentage of the best alignment
    """
    from Bio.Blast import NCBIWWW, NCBIXML
    from Bio.Seq import Seq

    max_attempts = 1
    attempts = 0
    max_runtime = 600  # 10 minutes

    while attempts < max_attempts:
        try:
            attempts += 1
            query_sequence = Seq(sequence)
            start_time = time.time()

            print(f"Submitting BLAST job (attempt {attempts}/{max_attempts})...")
            result_handle = NCBIWWW.qblast(program, database, query_sequence, expect=100, word_size=7, megablast=True)

            blast_records = NCBIXML.parse(result_handle)
            blast_record = None

            while time.time() - start_time < max_runtime:
                try:
                    blast_record = next(blast_records)
                    break
                except StopIteration:
                    return "No BLAST results found"
                except Exception:
                    if time.time() - start_time >= max_runtime:
                        if attempts < max_attempts:
                            print("BLAST job timeout exceeded. Resubmitting...")
                            break
                        else:
                            return "BLAST search failed after maximum attempts due to timeout"
                    time.sleep(1)

            if blast_record is None:
                if attempts < max_attempts:
                    continue
                else:
                    return "BLAST search failed after maximum attempts due to timeout"

            print(f"Number of alignments found: {len(blast_record.alignments)}")

            if blast_record.alignments:
                for alignment in blast_record.alignments:
                    for hsp in alignment.hsps:
                        return {
                            "hit_id": alignment.hit_id,
                            "hit_def": alignment.hit_def,
                            "accession": alignment.accession,
                            "e_value": hsp.expect,
                            "identity": (hsp.identities / float(hsp.align_length)) * 100,
                            "coverage": len(hsp.query) / len(sequence) * 100,
                        }
            else:
                return "No alignments found - sequence might be too short or low complexity"

        except Exception as e:
            if attempts < max_attempts:
                print(f"Error during BLAST search: {e}. Retrying...")
                time.sleep(2)
            else:
                return f"Error during BLAST search after maximum attempts: {e}"

    return "BLAST search failed after maximum attempts"


@tool
def query_reactome(prompt: str = None, endpoint: str = None, download: bool = False, output_dir: str = None, verbose: bool = True) -> dict:
    """
    Query the Reactome database using natural language or a direct endpoint.

    Args:
        prompt: Natural language query about biological pathways
        endpoint: Direct API endpoint or full URL
        download: Whether to download pathway diagrams
        output_dir: Directory to save downloaded files
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing the query results or error information
    """
    content_base_url = "https://reactome.org/ContentService"
    analysis_base_url = "https://reactome.org/AnalysisService"

    if prompt is None and endpoint is None:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if download and output_dir:
        os.makedirs(output_dir, exist_ok=True)

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "reactome.pkl")
        with open(schema_path, "rb") as f:
            reactome_schema = pickle.load(f)

        system_template = """
        You are a bioinformatics expert specialized in using the Reactome API.

        Based on the user's natural language request, determine the appropriate Reactome API endpoint and parameters.

        REACTOME API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "endpoint": The API endpoint to query (e.g., "data/pathways/PATHWAY_ID", "data/query/GENE_SYMBOL")
        2. "base": Which base URL to use ("content" for ContentService or "analysis" for AnalysisService)
        3. "params": An object containing query parameters specific to the endpoint
        4. "description": A brief description of what the query is doing

        SPECIAL NOTES:
        - Reactome has two primary APIs: ContentService (for retrieving specific pathway data) and AnalysisService (for analyzing gene lists)
        - For pathway queries, use "data/pathways/PATHWAY_ID" with the pathway stable identifier (e.g., R-HSA-73894)
        - For gene queries, use "data/query/GENE" with official gene symbol (e.g., "BRCA1")
        - For pathway diagrams, include "download: true" in your response if the query is for pathway visualization
        - Common human pathway IDs start with "R-HSA-"

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=reactome_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("endpoint", "")
        base = query_info.get("base", "content")
        params = query_info.get("params", {})
        description = query_info.get("description", "")
        should_download = query_info.get("download", download)

        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
    else:
        if endpoint.startswith("http"):
            if "ContentService" in endpoint:
                base = "content"
            elif "AnalysisService" in endpoint:
                base = "analysis"
            else:
                base = "content"
        else:
            base = "content"
        params = {}
        description = f"Direct query to Reactome {base} API: {endpoint}"
        should_download = download

    base_url = content_base_url if base == "content" else analysis_base_url

    if endpoint.startswith("/"):
        endpoint = endpoint[1:]
    url = endpoint if endpoint.startswith("http") else f"{base_url}/{endpoint}"

    api_result = _query_rest_api(endpoint=url, method="GET", params=params, description=description)

    if should_download and api_result.get("success") and "result" in api_result:
        result = api_result["result"]
        pathway_id = None
        if isinstance(result, dict):
            pathway_id = result.get("stId") or result.get("dbId")
        if pathway_id and output_dir:
            diagram_url = f"{content_base_url}/data/pathway/{pathway_id}/diagram"
            try:
                diagram_response = requests.get(diagram_url)
                diagram_response.raise_for_status()
                diagram_path = os.path.join(output_dir, f"{pathway_id}_diagram.png")
                with open(diagram_path, "wb") as f:
                    f.write(diagram_response.content)
                api_result["diagram_path"] = diagram_path
            except Exception as e:
                api_result["diagram_error"] = f"Failed to download diagram: {e}"

    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        return _format_query_results(api_result["result"])
    return api_result


@tool
def query_regulomedb(prompt: str = None, endpoint: str = None, verbose: bool = False) -> dict:
    """
    Query the RegulomeDB database using natural language or direct variant/coordinate specification.

    Args:
        prompt: Natural language query about regulatory elements
        endpoint: Direct endpoint URL or variant/coordinate specification
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing the query results or error information
    """
    base_url = "https://regulomedb.org/regulome-search/"

    if prompt is None and endpoint is None:
        return {"error": "Either a prompt, variant ID, or genomic coordinates must be provided"}

    if prompt and not endpoint:
        system_template = """
        You are a genomics expert specialized in using the RegulomeDB API.

        Based on the user's natural language request, extract the variant ID or genomic coordinates they want to query.

        Your response should be a JSON object with ONLY ONE of the following fields:
        1. "endpoint": The API endpoint to query (e.g., "https://regulomedb.org/regulome-search/?regions=chr11:5246919-5246919&genome=GRCh38")

        SPECIAL NOTES:
        - RegulomeDB only works with human genome data
        - Variant IDs should be rsIDs from dbSNP when possible. The endpoint should be in the format https://regulomedb.org/regulome-search/?regions=rsID&genome=GRCh38
        - Thumbnails for chip and chromatin should be in the format https://regulomedb.org/regulome-search?regions=chr11:5246919-5246919&genome=GRCh38/thumbnail=chip
        - Coordinates should be in GRCh37/hg19 format
        - For single base queries, use the same position for start and end (e.g., "chr11:5246919-5246919")
        - Chromosome should be specified with "chr" prefix (e.g., "chr11" not just "11")

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=None, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("endpoint", "")

        if not endpoint:
            return {"error": "Failed to extract a valid variant ID or coordinates from the prompt", "llm_response": llm_result.get("raw_response", "No response")}

    api_result = _query_rest_api(endpoint=endpoint, method="GET", headers={"Accept": "application/json"})

    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        api_result["result"] = _format_query_results(api_result["result"])
    return api_result


@tool
def query_pride(prompt: str = None, endpoint: str = None, max_results: int = 3) -> dict:
    """
    Query the PRIDE (PRoteomics IDEntifications) database using natural language or a direct endpoint.

    Args:
        prompt: Natural language query about proteomics data
        endpoint: The full endpoint to query
        max_results: Maximum number of results to return

    Returns:
        Dictionary containing the query results or error information
    """
    base_url = "https://www.ebi.ac.uk/pride/ws/archive/v2"

    if prompt is None and endpoint is None:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "pride.pkl")
        with open(schema_path, "rb") as f:
            pride_schema = pickle.load(f)

        system_template = """
        You are a proteomics expert specialized in using the PRIDE API.

        Based on the user's natural language request, determine the appropriate PRIDE API endpoint and parameters.

        PRIDE API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "endpoint": The full url endpoint to query
        2. "description": A brief description of what the query is doing

        SPECIAL NOTES:
        - PRIDE is a repository for proteomics data stored at EBI
        - Common endpoints include: "projects", "assays", "files", "proteins", "peptideevidences"
        - For searching projects, you can use parameters like "keyword", "species", "tissue", "disease"
        - For pagination, use "page" and "pageSize" parameters
        - Most results include PagingObject and FieldsObject structures

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=pride_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("endpoint", "")
        params = query_info.get("params", {})
        description = query_info.get("description", "")

        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
    else:
        params = {"pageSize": max_results, "page": 0}
        description = f"Direct query to PRIDE {endpoint}"

    if endpoint.startswith("/"):
        endpoint = f"{base_url}{endpoint}"
    elif not endpoint.startswith("http"):
        endpoint = f"{base_url}/{endpoint.lstrip('/')}"
    description = "Direct query to provided endpoint"

    return _query_rest_api(endpoint=endpoint, method="GET", params=params, description=description)


@tool
def query_gtopdb(prompt: str = None, endpoint: str = None, verbose: bool = True) -> dict:
    """
    Query the Guide to PHARMACOLOGY database (GtoPdb) using natural language or a direct endpoint.

    Args:
        prompt: Natural language query about drug targets, ligands, and interactions
        endpoint: Full API endpoint to query
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing the query results or error information
    """
    base_url = "https://www.guidetopharmacology.org/services"

    if prompt is None and endpoint is None:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "gtopdb.pkl")
        with open(schema_path, "rb") as f:
            gtopdb_schema = pickle.load(f)

        system_template = """
        You are a pharmacology expert specialized in using the Guide to PHARMACOLOGY API.

        Based on the user's natural language request, determine the appropriate GtoPdb API endpoint and parameters.

        GTOPDB API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "endpoint": The full API endpoint to query
        2. "description": A brief description of what the query is doing

        SPECIAL NOTES:
        - Main endpoints include: "targets", "ligands", "interactions", "diseases", "refs"
        - Target types include: "GPCR", "NHR", "LGIC", "VGIC", "OtherIC", "Enzyme", "CatalyticReceptor", "Transporter", "OtherProtein"
        - Ligand types include: "Synthetic organic", "Metabolite", "Natural product", "Endogenous peptide", "Peptide", "Antibody", "Inorganic", "Approved", "Withdrawn", "Labelled", "INN"
        - Interaction types include: "Activator", "Agonist", "Allosteric modulator", "Antagonist", "Antibody", "Channel blocker", "Gating inhibitor", "Inhibitor", "Subunit-specific"
        - For specific target/ligand details, use formats like "targets/{{targetId}}" or "ligands/{{ligandId}}"
        - For subresources, use formats like "targets/{{targetId}}/interactions" or "ligands/{{ligandId}}/structure"

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=gtopdb_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("endpoint", "")
        description = query_info.get("description", "")

        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
    else:
        description = f"Direct query to GtoPdb {endpoint}"

    if endpoint.startswith("/"):
        endpoint = f"{base_url}{endpoint}"
    elif not endpoint.startswith("http"):
        endpoint = f"{base_url}/{endpoint.lstrip('/')}"
    description = "Direct query to provided endpoint"

    api_result = _query_rest_api(endpoint=endpoint, method="GET", description=description)

    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        api_result["result"] = _format_query_results(api_result["result"])
    return api_result


@tool
def region_to_ccre_screen(coord_chrom: str, coord_start: int, coord_end: int, assembly: str = "GRCh38") -> str:
    """
    Given starting and ending coordinates, this function retrieves information of intersecting cCREs.

    Args:
        coord_chrom: Chromosome of the gene, formatted like 'chr12'
        coord_start: Starting chromosome coordinate
        coord_end: Ending chromosome coordinate
        assembly: Assembly of the genome, formatted like 'GRCh38'. Default is 'GRCh38'

    Returns:
        A detailed string explaining the steps and the intersecting cCRE data or any error encountered
    """
    steps: list = []
    try:
        steps.append(f"Starting cCRE data retrieval for coordinates: {coord_chrom}:{coord_start}-{coord_end} (Assembly: {assembly}).")

        url = "https://screen-beta-api.wenglab.org/dataws/cre_table"
        data = {"assembly": assembly, "coord_chrom": coord_chrom, "coord_start": coord_start, "coord_end": coord_end}
        steps.append("Sending POST request to API with the following data:")
        steps.append(str(data))

        response = requests.post(url, json=data)
        if not response.ok:
            raise Exception(f"Request failed with status code {response.status_code}. Response: {response.text}")

        steps.append("Request executed successfully. Parsing the response...")
        response_json = response.json()
        if "errors" in response_json:
            raise Exception(f"API error: {response_json['errors']}")

        def reduce_tokens(res_json):
            res = sorted(res_json["cres"], key=lambda x: x["dnase_zscore"], reverse=True)
            filtered_res = []
            for item in res:
                new_item = {
                    "chrom": item["chrom"],
                    "start": item["start"],
                    "len": item["len"],
                    "pct": item["pct"],
                    "ctcf_zscore": round(item["ctcf_zscore"], 2),
                    "dnase_zscore": round(item["dnase_zscore"], 2),
                    "enhancer_zscore": round(item["enhancer_zscore"], 2),
                    "promoter_zscore": round(item["promoter_zscore"], 2),
                    "accession": item["info"]["accession"],
                    "isproximal": item["info"]["isproximal"],
                    "concordance": item["info"]["concordant"],
                    "ctcfmax": round(item["info"]["ctcfmax"], 2),
                    "k4me3max": round(item["info"]["k4me3max"], 2),
                    "k27acmax": round(item["info"]["k27acmax"], 2),
                }
                filtered_res.append(new_item)
            return filtered_res

        filtered_data = reduce_tokens(response_json)
        if not filtered_data:
            steps.append(f"No intersecting cCREs found for coordinates: {coord_chrom}:{coord_start}-{coord_end}.")
            return "\n".join(steps + ["No cCRE data available for this genomic region."])

        ccre_data_string = f"Intersecting cCREs for {coord_chrom}:{coord_start}-{coord_end} (Assembly: {assembly}):\n"
        for i, ccre in enumerate(filtered_data, 1):
            ccre_data_string += (
                f"cCRE {i}:\n"
                f"  Chromosome: {ccre['chrom']}\n"
                f"  Start: {ccre['start']}\n"
                f"  Length: {ccre['len']}\n"
                f"  PCT: {ccre['pct']}\n"
                f"  CTCF Z-score: {ccre['ctcf_zscore']}\n"
                f"  DNase Z-score: {ccre['dnase_zscore']}\n"
                f"  Enhancer Z-score: {ccre['enhancer_zscore']}\n"
                f"  Promoter Z-score: {ccre['promoter_zscore']}\n"
                f"  Accession: {ccre['accession']}\n"
                f"  Is Proximal: {ccre['isproximal']}\n"
                f"  Concordance: {ccre['concordance']}\n"
                f"  CTCFmax: {ccre['ctcfmax']}\n"
                f"  K4me3max: {ccre['k4me3max']}\n"
                f"  K27acmax: {ccre['k27acmax']}\n\n"
            )

        steps.append(f"cCRE data successfully retrieved and formatted for {coord_chrom}:{coord_start}-{coord_end}.")
        return "\n".join(steps + [ccre_data_string])

    except Exception as e:
        steps.append(f"Exception encountered: {e}")
        return "\n".join(steps + [f"Error: {e}"])


@tool
def get_genes_near_ccre(accession: str, assembly: str, chromosome: str, k: int = 10) -> str:
    """
    Given a cCRE (Candidate cis-Regulatory Element), this function returns the k nearest genes sorted by distance.

    Args:
        accession: ENCODE Accession ID of query cCRE, e.g., EH38E1516980
        assembly: Assembly of the gene, e.g., 'GRCh38'
        chromosome: Chromosome of the gene, e.g., 'chr12'
        k: Number of nearby genes to return, sorted by distance. Default is 10

    Returns:
        Steps performed and the result
    """
    steps_log = f"Starting process with accession: {accession}, assembly: {assembly}, chromosome: {chromosome}, k: {k}\n"

    url = "https://screen-beta-api.wenglab.org/dataws/re_detail/nearbyGenomic"
    data = {"accession": accession, "assembly": assembly, "coord_chrom": chromosome}

    steps_log += "Sending POST request to API with given data.\n"
    response = requests.post(url, json=data)

    if not response.ok:
        steps_log += f"API request failed with response: {response.text}\n"
        return steps_log

    response_json = response.json()

    if "errors" in response_json:
        steps_log += f"API returned errors: {response_json['errors']}\n"
        return steps_log

    nearby_genes = response_json.get(accession, {}).get("nearby_genes", [])
    if not nearby_genes:
        steps_log += "No nearby genes found for the given accession.\n"
        return steps_log

    steps_log += "Successfully retrieved nearby genes. Sorting them by distance.\n"
    sorted_genes = sorted(nearby_genes, key=lambda x: x["distance"])[:k]

    steps_log += f"Returning the top {k} nearest genes.\n"
    steps_log += "Result:\n"

    for gene in sorted_genes:
        gene_name = gene.get("name", "Unknown")
        distance = gene.get("distance", "N/A")
        ensembl_id = gene.get("ensemblid_ver", "N/A")
        start = gene.get("start", "N/A")
        stop = gene.get("stop", "N/A")
        chrom = gene.get("chrom", "N/A")
        steps_log += f"Gene: {gene_name}, Distance: {distance}, Ensembl ID: {ensembl_id}, Chromosome: {chrom}, Start: {start}, Stop: {stop}\n"

    return steps_log


@tool
def query_remap(prompt: str = None, endpoint: str = None, verbose: bool = True) -> dict:
    """
    Query the ReMap database for regulatory elements and transcription factor binding sites.

    Args:
        prompt: Natural language query about transcription factors and binding sites
        endpoint: Full API endpoint to query
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing the query results or error information
    """
    base_url = "https://remap.univ-amu.fr/api/v1"

    if prompt is None and endpoint is None:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "remap.pkl")
        with open(schema_path, "rb") as f:
            remap_schema = pickle.load(f)

        system_template = """
        You are a genomics expert specialized in using the ReMap database API.

        Based on the user's natural language request, determine the appropriate ReMap API endpoint and parameters.

        REMAP API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "endpoint": The full url endpoint to query
        2. "description": A brief description of what the query is doing

        SPECIAL NOTES:
        - ReMap is a database of regulatory regions and transcription factor binding sites based on ChIP-seq experiments
        - Common endpoints include: "catalogue/tf" (transcription factors), "catalogue/biotype" (biotypes), "browse/peaks" (binding sites)
        - For searching binding sites, you can filter by transcription factor (tf), cell line, biotype, chromosome, etc.
        - Genomic coordinates should be specified with "chr", "start", and "end" parameters
        - For limiting results, use "limit" parameter (default is 100)

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=remap_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("endpoint", "")
        description = query_info.get("description", "")

        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
    else:
        description = f"Direct query to ReMap {endpoint}"

    if endpoint.startswith("/"):
        endpoint = f"{base_url}{endpoint}"
    elif not endpoint.startswith("http"):
        endpoint = f"{base_url}/{endpoint.lstrip('/')}"
    description = "Direct query to provided endpoint"

    api_result = _query_rest_api(endpoint=endpoint, method="GET", description=description)

    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        api_result["result"] = _format_query_results(api_result["result"])
    return api_result


@tool
def query_mpd(prompt: str = None, endpoint: str = None, verbose: bool = True) -> dict:
    """
    Query the Mouse Phenome Database (MPD) for mouse strain phenotype data.

    Args:
        prompt: Natural language query about mouse phenotypes, strains, or measurements
        endpoint: Full API endpoint to query
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing the query results or error information
    """
    base_url = "https://phenome.jax.org"

    if prompt is None and endpoint is None:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "mpd.pkl")
        with open(schema_path, "rb") as f:
            mpd_schema = pickle.load(f)

        system_template = """
        You are a mouse genetics expert specialized in using the Mouse Phenome Database (MPD) API.

        Based on the user's natural language request, determine the appropriate MPD API endpoint and parameters.

        MPD API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "endpoint": The full url endpoint to query (e.g. https://phenome.jax.org/api/strains)
        2. "description": A brief description of what the query is doing

        SPECIAL NOTES:
        - The MPD contains phenotype data for diverse strains of laboratory mice
        - Common endpoints include: "strains" (mouse strains), "measures" (phenotypic measurements), "genes" (gene info)
        - Use the url to construct the endpoint, not the endpoint name
        - Common mouse strains include: "C57BL/6J", "DBA/2J", "BALB/cJ", "A/J", "129S1/SvImJ"
        - Common phenotypic domains include: "behavior", "blood_chemistry", "body_weight", "cardiovascular", "growth", "metabolism"

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=mpd_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("endpoint", "")
        description = query_info.get("description", "")

        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
    else:
        description = f"Direct query to MPD {endpoint}"

    if endpoint.startswith("/"):
        endpoint = f"{base_url}{endpoint}"
    elif not endpoint.startswith("http"):
        endpoint = f"{base_url}/{endpoint.lstrip('/')}"
    description = "Direct query to provided endpoint"

    api_result = _query_rest_api(endpoint=endpoint, method="GET", description=description)

    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        api_result["result"] = _format_query_results(api_result["result"])
    return api_result


@tool
def query_emdb(prompt: str = None, endpoint: str = None, verbose: bool = True) -> dict:
    """
    Query the Electron Microscopy Data Bank (EMDB) for 3D macromolecular structures.

    Args:
        prompt: Natural language query about EM structures and associated data
        endpoint: Full API endpoint to query
        verbose: Whether to return detailed results

    Returns:
        Dictionary containing the query results or error information
    """
    base_url = "https://www.ebi.ac.uk/emdb/api"

    if prompt is None and endpoint is None:
        return {"error": "Either a prompt or an endpoint must be provided"}

    if prompt:
        schema_path = os.path.join(SCHEMA_DB_PATH, "emdb.pkl")
        with open(schema_path, "rb") as f:
            emdb_schema = pickle.load(f)

        system_template = """
        You are a structural biology expert specialized in using the Electron Microscopy Data Bank (EMDB) API.

        Based on the user's natural language request, determine the appropriate EMDB API endpoint and parameters.

        EMDB API SCHEMA:
        {schema}

        Your response should be a JSON object with the following fields:
        1. "endpoint": The API endpoint to query (e.g., "search", "entry/EMD-XXXXX")
        2. "params": An object containing query parameters specific to the endpoint
        3. "description": A brief description of what the query is doing

        SPECIAL NOTES:
        - EMDB contains 3D macromolecular structures determined by electron microscopy
        - Common endpoints include: "search" (search for entries), "entry/EMD-XXXXX" (specific entry details)
        - For searching, you can filter by resolution, specimen, authors, release date, etc.
        - Resolution filters should be specified with "resolution_low" and "resolution_high" parameters
        - For specific entry retrieval, use the format "entry/EMD-XXXXX" where XXXXX is the EMDB ID
        - Common specimen types include: "ribosome", "virus", "membrane protein", "filament"

        Return ONLY the JSON object with no additional text.
        """

        llm_result = _query_llm_for_api(prompt=prompt, schema=emdb_schema, system_template=system_template)
        if not llm_result["success"]:
            return llm_result

        query_info = llm_result["data"]
        endpoint = query_info.get("endpoint", "")
        params = query_info.get("params", {})
        description = query_info.get("description", "")

        if not endpoint:
            return {"error": "Failed to generate a valid endpoint from the prompt", "llm_response": llm_result.get("raw_response", "No response")}
    else:
        params = {}
        description = f"Direct query to EMDB {endpoint}"

    if endpoint.startswith("/"):
        endpoint = f"{base_url}{endpoint}"
    elif not endpoint.startswith("http"):
        endpoint = f"{base_url}/{endpoint.lstrip('/')}"
    description = "Direct query to provided endpoint"

    api_result = _query_rest_api(endpoint=endpoint, method="GET", params=params, description=description)

    if not verbose and "success" in api_result and api_result["success"] and "result" in api_result:
        api_result["result"] = _format_query_results(api_result["result"])
    return api_result
